{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GAN.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "-UyMqbG-lL4M",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Generative Adversarial Network\n",
        "\n",
        "Reference: https://github.com/eriklindernoren/Keras-GAN/"
      ]
    },
    {
      "metadata": {
        "id": "6qgo2nAR_kQf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Setting"
      ]
    },
    {
      "metadata": {
        "id": "Qa5fJ8mX_oDR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Mount Google Drive"
      ]
    },
    {
      "metadata": {
        "id": "sA88x9MVlkyT",
        "colab_type": "code",
        "outputId": "ab964cbc-21b2-4255-88ea-a10b4c224def",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "mount_folder = '/content/gdrive'\n",
        "drive.mount(mount_folder)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Kn57fZiuAs5i",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Go into the working directory"
      ]
    },
    {
      "metadata": {
        "id": "DaLsJmzzlovR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "app_folder = mount_folder + '/My Drive/'\n",
        "os.chdir(app_folder)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4EiMsntDDLSD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Input"
      ]
    },
    {
      "metadata": {
        "id": "tG_2rBm0DME9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "\n",
        "def get_banner_folder(prefixe = 'original'):\n",
        "  banner_folder = 'data/'+prefixe+'_steam_banners/'\n",
        "  Path(banner_folder).mkdir(exist_ok=True)  \n",
        "  return banner_folder\n",
        "\n",
        "def get_file_extension():\n",
        "  return '.jpg'\n",
        "  \n",
        "def get_banner_file_name(app_id):\n",
        "  return get_banner_folder() + str(app_id) + get_file_extension()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MbcQ-HYHDeKP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Banners which are a black background"
      ]
    },
    {
      "metadata": {
        "id": "vIk8YGbbDjQi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_skipped_banners():\n",
        "  skipped_app_ids = [396540]\n",
        "  skipped_banners = [get_banner_folder() + str(app_id) + get_file_extension() for app_id in skipped_app_ids]\n",
        "  return skipped_banners"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uWxWMRGsJ1Nr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Aggregate 56x56 images once, for faster processing later on"
      ]
    },
    {
      "metadata": {
        "id": "7kABedEdBv-P",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Aggregate Steam banners into a NumPy structure\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "WgZnY8dida2y",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import glob\n",
        "import numpy as np\n",
        "\n",
        "from time import time\n",
        "\n",
        "from keras.preprocessing.image import load_img\n",
        "\n",
        "def get_matrix_file_name(img_rows=56, img_cols=56, channels=1):\n",
        "  return 'data/banner_matrix_'+str(img_rows)+'x'+str(img_cols)+'x'+str(channels)+'.npy'\n",
        "\n",
        "\n",
        "def prepare_data_matrix(img_rows=56, img_cols=56, channels=1, prefixe = 'original', reset_matrix=False):     \n",
        "  all_image_names = glob.glob(get_banner_folder(prefixe) + '*' + get_file_extension())  \n",
        "  \n",
        "  # There is an issue with duplicates, e.g. 'ABC (1).jpg' but only when running on Google Drive:\n",
        "  image_names = [img for img in all_image_names if ' (' not in img]\n",
        "  \n",
        "  num_samples = len(image_names)\n",
        "    \n",
        "  if reset_matrix:\n",
        "    X_train = np.zeros((num_samples, img_rows, img_cols, channels))    \n",
        "  else:\n",
        "    try:\n",
        "      X_train = np.load(get_matrix_file_name(img_rows, img_cols, channels))\n",
        "    except FileNotFoundError:\n",
        "      X_train = np.zeros((num_samples, img_rows, img_cols, channels))    \n",
        "    \n",
        "  has_changed = False\n",
        "  start = time()\n",
        "  \n",
        "  for counter, image_name in enumerate(sorted(image_names)):    \n",
        "    \n",
        "    if np.any(X_train[counter,...]!=0) or (image_name in get_skipped_banners()):\n",
        "      continue\n",
        "    \n",
        "    if (counter+1) % 100 == 0:\n",
        "      print('Elapsed time: {:.2f} s'.format(time() - start))\n",
        "      start = time()      \n",
        "      print('Iteration {}/{}'.format(counter+1, num_samples))\n",
        "      if has_changed:\n",
        "        np.save(get_matrix_file_name(img_rows, img_cols, channels), X_train)\n",
        "        has_changed = False        \n",
        "\n",
        "    image = load_img(image_name, target_size=(img_rows, img_cols))    \n",
        "    has_changed = True\n",
        "    \n",
        "    # Grayscale\n",
        "    if channels==1:\n",
        "      image = np.expand_dims(np.mean(image, axis=2), axis=2)\n",
        "\n",
        "    X_train[counter, ...] = image    \n",
        "  \n",
        "  if has_changed:\n",
        "    print('Saving.')\n",
        "    np.save(get_matrix_file_name(img_rows, img_cols, channels), X_train)\n",
        "  \n",
        "  return X_train"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WYTI2ONiJF8L",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Choose image size and the number of channels (color vs. grayscale image). Preferably, choose a rather high image size, e.g. 56x56, so that the NumPy structure has a decent size but is not too large, e.g. about 2 GB if images have 3 color channels.\n",
        "\n",
        "If we need smaller images later on, we could load this dataset and downsample the stored images. The fact that we would not have to load the images from the disk would make the process fast enough."
      ]
    },
    {
      "metadata": {
        "id": "wDRNNhvTJJl0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "default_img_rows=56\n",
        "default_img_cols=56\n",
        "default_channels=3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tWFygNyCKmQy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Aggregate images, resized to 56x56 pixels"
      ]
    },
    {
      "metadata": {
        "id": "QHohApiTB9MV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_train = prepare_data_matrix(img_rows=default_img_rows, img_cols=default_img_cols, channels=default_channels, prefixe='resized', reset_matrix=False)  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NEAbymBDCOhT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Pre-processing"
      ]
    },
    {
      "metadata": {
        "id": "H0FNxN1_MRTn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Choose image size and the number of channels (color vs. grayscale image)"
      ]
    },
    {
      "metadata": {
        "id": "FXWevYr2MQn5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "img_rows=28\n",
        "img_cols=28\n",
        "channels=3\n",
        "\n",
        "# Color images cannot be created from stored grayscale images\n",
        "assert(channels <= default_channels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sZDJky2T5uxc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Resize images stored in X_train"
      ]
    },
    {
      "metadata": {
        "id": "CGuD9s0h5rzH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "\n",
        "input_file_name = get_matrix_file_name(default_img_rows, default_img_cols, default_channels)\n",
        "output_file_name = get_matrix_file_name(img_rows, img_cols, channels)\n",
        "\n",
        "if not Path(output_file_name).exists():\n",
        "\n",
        "  X_train = np.load(input_file_name)\n",
        "\n",
        "  num_samples = X_train.shape[0]\n",
        "\n",
        "  X_train_resized = np.zeros((num_samples, img_rows, img_cols, channels))\n",
        "  for index, image in enumerate(X_train):\n",
        "    resized_image = cv2.resize(image, (img_rows, img_cols))\n",
        "\n",
        "    if default_channels > 1:\n",
        "      if channels > 1:\n",
        "        pass\n",
        "      else:\n",
        "        resized_image = np.mean(resized_image, axis=2)\n",
        "        resized_image = np.expand_dims(resized_image, axis=2)\n",
        "    else:\n",
        "      resized_image = np.expand_dims(resized_image, axis=2)\n",
        "\n",
        "    X_train_resized[index, ...] = resized_image\n",
        "\n",
        "  np.save(output_file_name, X_train_resized)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-hhai2cvFmC6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Load pre-computed aggregate of resized Steam banners"
      ]
    },
    {
      "metadata": {
        "id": "1OTdRIYZq5gu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_train = np.load(get_matrix_file_name(img_rows, img_cols, channels))\n",
        "\n",
        "X_train.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5VZGh405ELwD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Display Steam banners of real games"
      ]
    },
    {
      "metadata": {
        "id": "rzefhJcO0KbU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "r = 5\n",
        "c = 5\n",
        "\n",
        "num_channels = X_train.shape[-1]\n",
        "\n",
        "fig, axs = plt.subplots(r, c)\n",
        "cnt = 0\n",
        "for i in range(r):\n",
        "    for j in range(c):\n",
        "        if num_channels > 1:\n",
        "          image = np.array(X_train[cnt, ...])\n",
        "        else:\n",
        "          image = 255 - np.array(X_train[cnt, :, :, 0])\n",
        "        # Reference: https://stackoverflow.com/a/51255361\n",
        "        axs[i,j].imshow(image.astype(np.uint8))\n",
        "        axs[i,j].axis('off')\n",
        "        cnt += 1\n",
        "plt.show()        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YUZpo06Z_8o0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Train GAN"
      ]
    },
    {
      "metadata": {
        "id": "AFq4vqiMAZ_I",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Reference: https://github.com/eriklindernoren/Keras-GAN/blob/master/gan/gan.py"
      ]
    },
    {
      "metadata": {
        "id": "hXka_JF5Gvxa",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Import Python modules"
      ]
    },
    {
      "metadata": {
        "id": "_o5fMSAvkl47",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.layers import Input, Dense, Reshape, Flatten, Dropout\n",
        "from keras.layers import BatchNormalization, Activation, ZeroPadding2D\n",
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
        "from keras.models import Sequential, Model\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "p-ckfvMej80B",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class GAN():\n",
        "    # CODE CHANGED BELOW\n",
        "    def __init__(self, img_rows=11, img_cols=23, channels=3):\n",
        "        self.img_rows = img_rows # 215\n",
        "        self.img_cols = img_cols # 460\n",
        "        self.channels = channels # 3\n",
        "        self.img_shape = (self.img_rows, self.img_cols, self.channels)\n",
        "        self.latent_dim = 100\n",
        "\n",
        "        # CODE CHANGED BELOW  \n",
        "        self.image_folder = 'images_steam_gan/'\n",
        "        Path(self.image_folder).mkdir(exist_ok=True)             \n",
        "        \n",
        "        optimizer = Adam(0.0002, 0.5)\n",
        "\n",
        "        # Build and compile the discriminator\n",
        "        self.discriminator = self.build_discriminator()\n",
        "        self.discriminator.compile(loss='binary_crossentropy',\n",
        "            optimizer=optimizer,\n",
        "            metrics=['accuracy'])\n",
        "\n",
        "        # Build the generator\n",
        "        self.generator = self.build_generator()\n",
        "\n",
        "        # The generator takes noise as input and generates imgs\n",
        "        z = Input(shape=(self.latent_dim,))\n",
        "        img = self.generator(z)\n",
        "\n",
        "        # For the combined model we will only train the generator\n",
        "        self.discriminator.trainable = False\n",
        "\n",
        "        # The discriminator takes generated images as input and determines validity\n",
        "        validity = self.discriminator(img)\n",
        "\n",
        "        # The combined model  (stacked generator and discriminator)\n",
        "        # Trains the generator to fool the discriminator\n",
        "        self.combined = Model(z, validity)\n",
        "        self.combined.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
        "\n",
        "\n",
        "    def build_generator(self):\n",
        "\n",
        "        model = Sequential()\n",
        "\n",
        "        model.add(Dense(256, input_dim=self.latent_dim))\n",
        "        model.add(LeakyReLU(alpha=0.2))\n",
        "        model.add(BatchNormalization(momentum=0.8))\n",
        "        model.add(Dense(512))\n",
        "        model.add(LeakyReLU(alpha=0.2))\n",
        "        model.add(BatchNormalization(momentum=0.8))\n",
        "        model.add(Dense(1024))\n",
        "        model.add(LeakyReLU(alpha=0.2))\n",
        "        model.add(BatchNormalization(momentum=0.8))\n",
        "        model.add(Dense(np.prod(self.img_shape)))\n",
        "        model.add(Activation('tanh'))\n",
        "        model.add(Reshape(self.img_shape))\n",
        "\n",
        "        model.summary()\n",
        "\n",
        "        noise = Input(shape=(self.latent_dim,))\n",
        "        img = model(noise)\n",
        "\n",
        "        return Model(noise, img)\n",
        "\n",
        "    def build_discriminator(self):\n",
        "\n",
        "        model = Sequential()\n",
        "\n",
        "        model.add(Flatten(input_shape=self.img_shape))\n",
        "        model.add(Dense(512))\n",
        "        model.add(LeakyReLU(alpha=0.2))\n",
        "        model.add(Dense(256))\n",
        "        model.add(LeakyReLU(alpha=0.2))\n",
        "        model.add(Dense(1, activation='sigmoid'))\n",
        "        model.summary()\n",
        "\n",
        "        img = Input(shape=self.img_shape)\n",
        "        validity = model(img)\n",
        "\n",
        "        return Model(img, validity)\n",
        "\n",
        "    def train(self, epochs, batch_size=128, sample_interval=50):\n",
        "\n",
        "        # Load the dataset\n",
        "        # CODE CHANGED BELOW\n",
        "        X_train = np.load(get_matrix_file_name(self.img_rows, self.img_cols, self.channels))\n",
        "        if self.channels == 1:\n",
        "          X_train = np.mean(X_train, axis=3)\n",
        "\n",
        "        # Rescale -1 to 1\n",
        "        X_train = X_train / 127.5 - 1.\n",
        "        # CODE CHANGED BELOW\n",
        "        if self.channels == 1:\n",
        "          X_train = np.expand_dims(X_train, axis=3)\n",
        "\n",
        "        # Adversarial ground truths\n",
        "        valid = np.ones((batch_size, 1))\n",
        "        fake = np.zeros((batch_size, 1))\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "\n",
        "            # ---------------------\n",
        "            #  Train Discriminator\n",
        "            # ---------------------\n",
        "\n",
        "            # Select a random batch of images\n",
        "            idx = np.random.randint(0, X_train.shape[0], batch_size)\n",
        "            imgs = X_train[idx]\n",
        "\n",
        "            noise = np.random.normal(0, 1, (batch_size, self.latent_dim))\n",
        "\n",
        "            # Generate a batch of new images\n",
        "            gen_imgs = self.generator.predict(noise)\n",
        "\n",
        "            # Train the discriminator\n",
        "            d_loss_real = self.discriminator.train_on_batch(imgs, valid)\n",
        "            d_loss_fake = self.discriminator.train_on_batch(gen_imgs, fake)\n",
        "            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
        "\n",
        "            # ---------------------\n",
        "            #  Train Generator\n",
        "            # ---------------------\n",
        "\n",
        "            noise = np.random.normal(0, 1, (batch_size, self.latent_dim))\n",
        "\n",
        "            # Train the generator (to have the discriminator label samples as valid)\n",
        "            g_loss = self.combined.train_on_batch(noise, valid)\n",
        "\n",
        "            # Plot the progress\n",
        "            if epoch % 100 == 0:\n",
        "              print (\"%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" % (epoch, d_loss[0], 100*d_loss[1], g_loss))\n",
        "\n",
        "            # If at save interval => save generated image samples\n",
        "            if epoch % sample_interval == 0:\n",
        "                self.sample_images(epoch)\n",
        "\n",
        "    def sample_images(self, epoch):\n",
        "        r, c = 5, 5\n",
        "        noise = np.random.normal(0, 1, (r * c, self.latent_dim))\n",
        "        gen_imgs = self.generator.predict(noise)\n",
        "\n",
        "        # Rescale images 0 - 1\n",
        "        gen_imgs = 0.5 * gen_imgs + 0.5\n",
        "\n",
        "        fig, axs = plt.subplots(r, c)\n",
        "        cnt = 0\n",
        "        for i in range(r):\n",
        "            for j in range(c):\n",
        "              # CODE CHANGED BELOW\n",
        "                if gen_imgs.shape[-1]>1:\n",
        "                  axs[i,j].imshow(gen_imgs[cnt, :,:,:])\n",
        "                else:\n",
        "                  axs[i,j].imshow(gen_imgs[cnt, :,:,0])                    \n",
        "                axs[i,j].axis('off')\n",
        "                cnt += 1\n",
        "        # CODE CHANGED BELOW                \n",
        "        fig.savefig(self.image_folder + \"%d.png\" % epoch)\n",
        "        plt.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uYBO_z2Kki86",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "gan = GAN(img_rows=img_rows, img_cols=img_cols, channels=channels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Kj-rAIuyffPt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "num_iter = 30000\n",
        "gan.train(epochs=num_iter+1, batch_size=32, sample_interval=200)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Pqab6NDhAUyR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Display sampled banners"
      ]
    },
    {
      "metadata": {
        "id": "75EokdnOFFws",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "plt.imshow(plt.imread(gan.image_folder + str(num_iter) + '.png'))\n",
        "plt.axis('off')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KHn4bahWAAN1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Train WGAN"
      ]
    },
    {
      "metadata": {
        "id": "9_PqcB-eHBdZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Reference: https://github.com/eriklindernoren/Keras-GAN/blob/master/wgan/wgan.py"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "YDFxF7V4HByl"
      },
      "cell_type": "markdown",
      "source": [
        "Import Python modules"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "6T5zu-SIHByu",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.layers import Input, Dense, Reshape, Flatten, Dropout\n",
        "from keras.layers import BatchNormalization, Activation, ZeroPadding2D\n",
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
        "from keras.models import Sequential, Model\n",
        "from keras.optimizers import RMSprop\n",
        "\n",
        "import keras.backend as K\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lHelm7n-s7o6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class WGAN():\n",
        "    # CODE CHANGED BELOW  \n",
        "    def __init__(self, img_rows=11, img_cols=23, channels=3):\n",
        "        self.img_rows = img_rows # 215\n",
        "        self.img_cols = img_cols # 460\n",
        "        self.channels = channels # 3\n",
        "        self.img_shape = (self.img_rows, self.img_cols, self.channels)\n",
        "        self.latent_dim = 100\n",
        "\n",
        "        # CODE CHANGED BELOW  \n",
        "        self.image_folder = 'images_steam_wgan/'\n",
        "        Path(self.image_folder).mkdir(exist_ok=True)                \n",
        "        \n",
        "        # Following parameter and optimizer set as recommended in paper\n",
        "        self.n_critic = 5\n",
        "        self.clip_value = 0.01\n",
        "        optimizer = RMSprop(lr=0.00005)\n",
        "\n",
        "        # Build and compile the critic\n",
        "        self.critic = self.build_critic()\n",
        "        self.critic.compile(loss=self.wasserstein_loss,\n",
        "            optimizer=optimizer,\n",
        "            metrics=['accuracy'])\n",
        "\n",
        "        # Build the generator\n",
        "        self.generator = self.build_generator()\n",
        "\n",
        "        # The generator takes noise as input and generated imgs\n",
        "        z = Input(shape=(self.latent_dim,))\n",
        "        img = self.generator(z)\n",
        "\n",
        "        # For the combined model we will only train the generator\n",
        "        self.critic.trainable = False\n",
        "\n",
        "        # The critic takes generated images as input and determines validity\n",
        "        valid = self.critic(img)\n",
        "\n",
        "        # The combined model  (stacked generator and critic)\n",
        "        self.combined = Model(z, valid)\n",
        "        self.combined.compile(loss=self.wasserstein_loss,\n",
        "            optimizer=optimizer,\n",
        "            metrics=['accuracy'])\n",
        "\n",
        "    def wasserstein_loss(self, y_true, y_pred):\n",
        "        return K.mean(y_true * y_pred)\n",
        "\n",
        "    def build_generator(self):\n",
        "\n",
        "        model = Sequential()\n",
        "\n",
        "        model.add(Dense(128 * 7 * 7, activation=\"relu\", input_dim=self.latent_dim))\n",
        "        model.add(Reshape((7, 7, 128)))\n",
        "        model.add(UpSampling2D())\n",
        "        model.add(Conv2D(128, kernel_size=4, padding=\"same\"))\n",
        "        model.add(BatchNormalization(momentum=0.8))\n",
        "        model.add(Activation(\"relu\"))\n",
        "        model.add(UpSampling2D())\n",
        "        model.add(Conv2D(64, kernel_size=4, padding=\"same\"))\n",
        "        model.add(BatchNormalization(momentum=0.8))\n",
        "        model.add(Activation(\"relu\"))\n",
        "        model.add(Conv2D(self.channels, kernel_size=4, padding=\"same\"))\n",
        "        # CODE CHANGED BELOW  \n",
        "        if self.img_shape[0] != 28 or self.img_shape[1] != 28:\n",
        "          model.add(Flatten())\n",
        "          model.add(Dense(np.prod(self.img_shape)))\n",
        "        model.add(Activation('tanh'))\n",
        "        # CODE CHANGED BELOW  \n",
        "        if self.img_shape[0] != 28 or self.img_shape[1] != 28:\n",
        "          model.add(Reshape(self.img_shape))      \n",
        "\n",
        "        model.summary()\n",
        "\n",
        "        noise = Input(shape=(self.latent_dim,))\n",
        "        img = model(noise)\n",
        "\n",
        "        return Model(noise, img)\n",
        "\n",
        "    def build_critic(self):\n",
        "\n",
        "        model = Sequential()\n",
        "\n",
        "        model.add(Conv2D(16, kernel_size=3, strides=2, input_shape=self.img_shape, padding=\"same\"))\n",
        "        model.add(LeakyReLU(alpha=0.2))\n",
        "        model.add(Dropout(0.25))\n",
        "        model.add(Conv2D(32, kernel_size=3, strides=2, padding=\"same\"))\n",
        "        model.add(ZeroPadding2D(padding=((0,1),(0,1))))\n",
        "        model.add(BatchNormalization(momentum=0.8))\n",
        "        model.add(LeakyReLU(alpha=0.2))\n",
        "        model.add(Dropout(0.25))\n",
        "        model.add(Conv2D(64, kernel_size=3, strides=2, padding=\"same\"))\n",
        "        model.add(BatchNormalization(momentum=0.8))\n",
        "        model.add(LeakyReLU(alpha=0.2))\n",
        "        model.add(Dropout(0.25))\n",
        "        model.add(Conv2D(128, kernel_size=3, strides=1, padding=\"same\"))\n",
        "        model.add(BatchNormalization(momentum=0.8))\n",
        "        model.add(LeakyReLU(alpha=0.2))\n",
        "        model.add(Dropout(0.25))\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(1))\n",
        "\n",
        "        model.summary()\n",
        "\n",
        "        img = Input(shape=self.img_shape)\n",
        "        validity = model(img)\n",
        "\n",
        "        return Model(img, validity)\n",
        "\n",
        "    def train(self, epochs, batch_size=128, sample_interval=50):\n",
        "\n",
        "        # Load the dataset\n",
        "        # CODE CHANGED BELOW\n",
        "        X_train = np.load(get_matrix_file_name(self.img_rows, self.img_cols, self.channels))\n",
        "        if self.channels == 1:\n",
        "          X_train = np.mean(X_train, axis=3)\n",
        "       \n",
        "        # Rescale -1 to 1\n",
        "        X_train = (X_train.astype(np.float32) - 127.5) / 127.5\n",
        "        # CODE CHANGED BELOW\n",
        "        if self.channels == 1:        \n",
        "          X_train = np.expand_dims(X_train, axis=3)\n",
        "\n",
        "        # Adversarial ground truths\n",
        "        valid = -np.ones((batch_size, 1))\n",
        "        fake = np.ones((batch_size, 1))\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "\n",
        "            for _ in range(self.n_critic):\n",
        "\n",
        "                # ---------------------\n",
        "                #  Train Discriminator\n",
        "                # ---------------------\n",
        "\n",
        "                # Select a random batch of images\n",
        "                idx = np.random.randint(0, X_train.shape[0], batch_size)\n",
        "                imgs = X_train[idx]\n",
        "                \n",
        "                # Sample noise as generator input\n",
        "                noise = np.random.normal(0, 1, (batch_size, self.latent_dim))\n",
        "\n",
        "                # Generate a batch of new images\n",
        "                gen_imgs = self.generator.predict(noise)\n",
        "                \n",
        "                # Train the critic\n",
        "                d_loss_real = self.critic.train_on_batch(imgs, valid)\n",
        "                d_loss_fake = self.critic.train_on_batch(gen_imgs, fake)\n",
        "                d_loss = 0.5 * np.add(d_loss_fake, d_loss_real)\n",
        "\n",
        "                # Clip critic weights\n",
        "                for l in self.critic.layers:\n",
        "                    weights = l.get_weights()\n",
        "                    weights = [np.clip(w, -self.clip_value, self.clip_value) for w in weights]\n",
        "                    l.set_weights(weights)\n",
        "\n",
        "\n",
        "            # ---------------------\n",
        "            #  Train Generator\n",
        "            # ---------------------\n",
        "\n",
        "            g_loss = self.combined.train_on_batch(noise, valid)\n",
        "\n",
        "            # Plot the progress\n",
        "            if epoch % 100 == 0:\n",
        "              print (\"%d [D loss: %f] [G loss: %f]\" % (epoch, 1 - d_loss[0], 1 - g_loss[0]))\n",
        "\n",
        "            # If at save interval => save generated image samples\n",
        "            if epoch % sample_interval == 0:\n",
        "                self.sample_images(epoch)\n",
        "\n",
        "    def sample_images(self, epoch):\n",
        "        r, c = 5, 5\n",
        "        noise = np.random.normal(0, 1, (r * c, self.latent_dim))\n",
        "        gen_imgs = self.generator.predict(noise)\n",
        "\n",
        "        # Rescale images 0 - 1\n",
        "        gen_imgs = 0.5 * gen_imgs + 0.5\n",
        "\n",
        "        fig, axs = plt.subplots(r, c)\n",
        "        cnt = 0\n",
        "        for i in range(r):\n",
        "            for j in range(c):\n",
        "                # CODE CHANGED BELOW\n",
        "                if gen_imgs.shape[-1]>1:\n",
        "                  axs[i,j].imshow(gen_imgs[cnt, :,:,:])\n",
        "                else:\n",
        "                  axs[i,j].imshow(gen_imgs[cnt, :,:,0])\n",
        "                axs[i,j].axis('off')\n",
        "                cnt += 1\n",
        "        # CODE CHANGED BELOW                \n",
        "        fig.savefig(self.image_folder + \"%d.png\" % epoch)\n",
        "        plt.close()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RsDHwSmOs8Ac",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "wgan = WGAN(img_rows=img_rows, img_cols=img_cols, channels=channels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "R5CeJxzKfkFT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "num_iter = 4000\n",
        "wgan.train(epochs=num_iter+1, batch_size=32, sample_interval=50)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Qd61Bzh-AShp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Display sampled banners"
      ]
    },
    {
      "metadata": {
        "id": "PIYxY9P2Fks1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "plt.imshow(plt.imread(wgan.image_folder + str(num_iter) + '.png'))\n",
        "plt.axis('off')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Dxq0QsEqAC-J",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Train DCGAN"
      ]
    },
    {
      "metadata": {
        "id": "6_0YhJVlHjhA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Reference: https://github.com/eriklindernoren/Keras-GAN/blob/master/dcgan/dcgan.py"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "jbwtDxhDHna6"
      },
      "cell_type": "markdown",
      "source": [
        "Import Python modules"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "EfqjEiNVHna_",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.layers import Input, Dense, Reshape, Flatten, Dropout\n",
        "from keras.layers import BatchNormalization, Activation, ZeroPadding2D\n",
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
        "from keras.models import Sequential, Model\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lkmyQkyWtrJh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class DCGAN():\n",
        "    # CODE CHANGED BELOW  \n",
        "    def __init__(self, img_rows=11, img_cols=23, channels=3):\n",
        "        # Input shape      \n",
        "        self.img_rows = img_rows # 215\n",
        "        self.img_cols = img_cols # 460\n",
        "        self.channels = channels # 3\n",
        "        self.img_shape = (self.img_rows, self.img_cols, self.channels)\n",
        "        self.latent_dim = 100\n",
        "        \n",
        "        # CODE CHANGED BELOW  \n",
        "        self.image_folder = 'images_steam_dcgan/'\n",
        "        Path(self.image_folder).mkdir(exist_ok=True)                \n",
        "        \n",
        "        optimizer = Adam(0.0002, 0.5)\n",
        "\n",
        "        # Build and compile the discriminator\n",
        "        self.discriminator = self.build_discriminator()\n",
        "        self.discriminator.compile(loss='binary_crossentropy',\n",
        "            optimizer=optimizer,\n",
        "            metrics=['accuracy'])\n",
        "\n",
        "        # Build the generator\n",
        "        self.generator = self.build_generator()\n",
        "\n",
        "        # The generator takes noise as input and generates imgs\n",
        "        z = Input(shape=(self.latent_dim,))\n",
        "        img = self.generator(z)\n",
        "\n",
        "        # For the combined model we will only train the generator\n",
        "        self.discriminator.trainable = False\n",
        "\n",
        "        # The discriminator takes generated images as input and determines validity\n",
        "        valid = self.discriminator(img)\n",
        "\n",
        "        # The combined model  (stacked generator and discriminator)\n",
        "        # Trains the generator to fool the discriminator\n",
        "        self.combined = Model(z, valid)\n",
        "        self.combined.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
        "\n",
        "    def build_generator(self):\n",
        "\n",
        "        model = Sequential()\n",
        "\n",
        "        model.add(Dense(128 * 7 * 7, activation=\"relu\", input_dim=self.latent_dim))\n",
        "        model.add(Reshape((7, 7, 128)))\n",
        "        model.add(UpSampling2D())\n",
        "        model.add(Conv2D(128, kernel_size=3, padding=\"same\"))\n",
        "        model.add(BatchNormalization(momentum=0.8))\n",
        "        model.add(Activation(\"relu\"))\n",
        "        model.add(UpSampling2D())\n",
        "        model.add(Conv2D(64, kernel_size=3, padding=\"same\"))\n",
        "        model.add(BatchNormalization(momentum=0.8))\n",
        "        model.add(Activation(\"relu\"))\n",
        "        model.add(Conv2D(self.channels, kernel_size=3, padding=\"same\"))\n",
        "        # CODE CHANGED BELOW  \n",
        "        if self.img_shape[0] != 28 or self.img_shape[1] != 28:\n",
        "          model.add(Flatten())\n",
        "          model.add(Dense(np.prod(self.img_shape)))\n",
        "        model.add(Activation('tanh'))\n",
        "        # CODE CHANGED BELOW  \n",
        "        if self.img_shape[0] != 28 or self.img_shape[1] != 28:\n",
        "          model.add(Reshape(self.img_shape))\n",
        "\n",
        "        model.summary()\n",
        "\n",
        "        noise = Input(shape=(self.latent_dim,))\n",
        "        img = model(noise)\n",
        "\n",
        "        return Model(noise, img)\n",
        "\n",
        "    def build_discriminator(self):\n",
        "\n",
        "        model = Sequential()\n",
        "\n",
        "        model.add(Conv2D(32, kernel_size=3, strides=2, input_shape=self.img_shape, padding=\"same\"))\n",
        "        model.add(LeakyReLU(alpha=0.2))\n",
        "        model.add(Dropout(0.25))\n",
        "        model.add(Conv2D(64, kernel_size=3, strides=2, padding=\"same\"))\n",
        "        model.add(ZeroPadding2D(padding=((0,1),(0,1))))\n",
        "        model.add(BatchNormalization(momentum=0.8))\n",
        "        model.add(LeakyReLU(alpha=0.2))\n",
        "        model.add(Dropout(0.25))\n",
        "        model.add(Conv2D(128, kernel_size=3, strides=2, padding=\"same\"))\n",
        "        model.add(BatchNormalization(momentum=0.8))\n",
        "        model.add(LeakyReLU(alpha=0.2))\n",
        "        model.add(Dropout(0.25))\n",
        "        model.add(Conv2D(256, kernel_size=3, strides=1, padding=\"same\"))\n",
        "        model.add(BatchNormalization(momentum=0.8))\n",
        "        model.add(LeakyReLU(alpha=0.2))\n",
        "        model.add(Dropout(0.25))\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "        model.summary()\n",
        "\n",
        "        img = Input(shape=self.img_shape)\n",
        "        validity = model(img)\n",
        "\n",
        "        return Model(img, validity)\n",
        "\n",
        "    def train(self, epochs, batch_size=128, save_interval=50):\n",
        "\n",
        "        # Load the dataset\n",
        "        # CODE CHANGED BELOW\n",
        "        X_train = np.load(get_matrix_file_name(self.img_rows, self.img_cols, self.channels))\n",
        "        if self.channels == 1:\n",
        "          X_train = np.mean(X_train, axis=3)\n",
        "       \n",
        "        # Rescale -1 to 1\n",
        "        X_train = X_train / 127.5 - 1.\n",
        "        # CODE CHANGED BELOW\n",
        "        if self.channels == 1:                \n",
        "          X_train = np.expand_dims(X_train, axis=3)\n",
        "\n",
        "        # Adversarial ground truths\n",
        "        valid = np.ones((batch_size, 1))\n",
        "        fake = np.zeros((batch_size, 1))\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "\n",
        "            # ---------------------\n",
        "            #  Train Discriminator\n",
        "            # ---------------------\n",
        "\n",
        "            # Select a random half of images\n",
        "            idx = np.random.randint(0, X_train.shape[0], batch_size)\n",
        "            imgs = X_train[idx]\n",
        "\n",
        "            # Sample noise and generate a batch of new images\n",
        "            noise = np.random.normal(0, 1, (batch_size, self.latent_dim))\n",
        "            gen_imgs = self.generator.predict(noise)\n",
        "\n",
        "            # Train the discriminator (real classified as ones and generated as zeros)\n",
        "            d_loss_real = self.discriminator.train_on_batch(imgs, valid)\n",
        "            d_loss_fake = self.discriminator.train_on_batch(gen_imgs, fake)\n",
        "            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
        "\n",
        "            # ---------------------\n",
        "            #  Train Generator\n",
        "            # ---------------------\n",
        "\n",
        "            # Train the generator (wants discriminator to mistake images as real)\n",
        "            g_loss = self.combined.train_on_batch(noise, valid)\n",
        "\n",
        "            # Plot the progress\n",
        "            if epoch % 100 == 0:\n",
        "              print (\"%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" % (epoch, d_loss[0], 100*d_loss[1], g_loss))\n",
        "\n",
        "            # If at save interval => save generated image samples\n",
        "            if epoch % save_interval == 0:\n",
        "                self.save_imgs(epoch)\n",
        "\n",
        "    def save_imgs(self, epoch):\n",
        "        r, c = 5, 5\n",
        "        noise = np.random.normal(0, 1, (r * c, self.latent_dim))\n",
        "        gen_imgs = self.generator.predict(noise)\n",
        "\n",
        "        # Rescale images 0 - 1\n",
        "        gen_imgs = 0.5 * gen_imgs + 0.5\n",
        "\n",
        "        fig, axs = plt.subplots(r, c)\n",
        "        cnt = 0\n",
        "        for i in range(r):\n",
        "            for j in range(c):\n",
        "                # CODE CHANGED BELOW\n",
        "                if gen_imgs.shape[-1]>1:\n",
        "                  axs[i,j].imshow(gen_imgs[cnt, :,:,:])\n",
        "                else:\n",
        "                  axs[i,j].imshow(gen_imgs[cnt, :,:,0]) \n",
        "                axs[i,j].axis('off')\n",
        "                cnt += 1\n",
        "        # CODE CHANGED BELOW                \n",
        "        fig.savefig(self.image_folder + \"%d.png\" % epoch)\n",
        "        plt.close()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HKjVbRW3trOY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "dcgan = DCGAN(img_rows=img_rows, img_cols=img_cols, channels=channels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MmlEFmLMfpP6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "num_iter = 4000\n",
        "dcgan.train(epochs=num_iter+1, batch_size=32, save_interval=50)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AShrVe4lAGTR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Display sampled banners"
      ]
    },
    {
      "metadata": {
        "id": "BIy8bzCxFmzK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "plt.imshow(plt.imread(dcgan.image_folder + str(num_iter) + '.png'))\n",
        "plt.axis('off')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}